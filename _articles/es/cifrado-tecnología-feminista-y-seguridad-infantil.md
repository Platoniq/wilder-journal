---
layout: article
volume-uid: wilder-journal-2
category: interviews
published: true
date: 2025-12-23T11:02:00.000+01:00
date-updated: 2025-12-23T11:02:00.000+01:00
article-order: 14
uid: Cifrado, tecnología feminista y seguridad infantil
title: Chayn como espacio digital de reivindicación (y protección) feminista
description: Chayn como espacio digital de reivindicación (y protección) feminista
author: Cristian Palazzi
author_uids:
  - cristian-palazzi
interviewee: Hera Hussein
cover:
  path: /media/articles/heroes/captura-de-pantalla-2025-12-23-a-las-11.05.30.png
  mobile: /assets/media/no_image-hero.png
  thumbnail: /assets/media/no_image-thumbnail.png
  alt: HERA
  credits: Hera
  caption: Hera
related_article_uids: []
stickers:
  layout: layout-none
  sticker_one_animation: animation-none
  sticker_two_animation: animation-none
call_to_action: cta-donate
image:
  path: /assets/media/no_image-social_media.png
---
**Entrevista con Hera Hussein**

**Cifrado, tecnología feminista y seguridad infantil**

Hera Hussein es la fundadora y directora ejecutiva de CHAYN, una organización sin ánimo de lucro global que crea recursos en línea para abordar la violencia de género. Los materiales multilingües de Chayn, diseñados por supervivientes, han llegado a más de 700 000 personas. Criada en Pakistán y residente en el Reino Unido, Hera supo desde muy temprano que quería luchar contra la violencia contra las mujeres. Cree en el uso de tecnología de código abierto, diseño basado en el trauma y enfoques llenos de esperanza para resolver problemas globales urgentes. Hera es miembro de Ashoka y ha sido reconocida por Forbes 30 Under 30, MIT Technology Review's Innovators Under 35 y como European Young Leader 2020.

**P: Tu trabajo con Chayn ha transformado la forma en que la tecnología puede apoyar a las sobrevivientes de la violencia de género. ¿Cómo te llevó tu trayectoria personal a fundar Chayn y a abordar la tecnología desde una perspectiva feminista?**

R: Fundé Chayn cuando tenía 23 años. Ahora tengo 36 y, sin duda, he crecido junto con la organización. Lo hice porque estaba ayudando a dos amigas, ambas de Pakistán, a escapar de relaciones abusivas. Una estaba en el Reino Unido, donde yo estudiaba, y la otra en Pakistán, donde crecí. Me di cuenta de que ambas tenían dificultades para obtener apoyo: comprender lo que les estaba pasando, reconocer que no era culpa suya, lidiar con el impacto emocional y encontrar organizaciones que pudieran ayudarles con apoyo legal, vivienda o asesoramiento.

No pude encontrar esa información en Internet. En la era digital, creía que debería haber espacios donde las personas pudieran buscar ayuda incluso si no podían hacer una llamada o ir a algún sitio físicamente. Por eso fundé Chayn.

A lo largo de los años, he abordado la tecnología desde una perspectiva feminista, porque para mí siempre ha sido algo natural. Crecí en un hogar empoderador y sentía que la tecnología me pertenecía. Recuerdo que tomé mi primera clase de informática a los 9 o 10 años. Era la única chica entre 30 hombres de entre 18 y 30 años. Mi madre me preguntó si me parecía bien y le dije que sí.

Cuando empecé a trabajar en tecnología, enseguida me di cuenta de lo dominado que estaba por los hombres. La industria daba prioridad a la velocidad, el coste y lo «cool», pero lo «cool» lo definían los hombres, principalmente hombres blancos occidentales, que creaban productos globales. Así que me pregunté: ¿cómo sería la tecnología si personas más diversas tuvieran voz en ella?

En Chayn, aplicamos un enfoque feminista a toda nuestra tecnología. Diseñamos, construimos y utilizamos la tecnología guiándonos por principios feministas.

**P: Hablas de diseño basado en el trauma y enmarcado lleno de esperanza, no solo de principios feministas. ¿Cómo influyen estos principios en la forma en que Chayn crea herramientas y recursos digitales?**

R: Con el tiempo, hemos desarrollado un conjunto de principios de diseño basados en el trauma que guían todo lo que creamos, ya sean políticas, tecnología o contenido, para personas que pueden haber sufrido traumas graves.

Por ejemplo, recientemente hemos lanzado una herramienta de IA que ayuda a las víctimas de abusos basados en imágenes a enviar solicitudes de retirada a las plataformas tecnológicas. La hemos diseñado conjuntamente con 60 víctimas de 20 países. Han influido en todo, desde la privacidad y la usabilidad hasta el lenguaje que utilizamos y la claridad sobre lo que la herramienta puede y no puede hacer.

Nuestros principios clave incluyen la agencia, lo que significa que los usuarios tienen opciones reales, y la responsabilidad, lo que significa que somos transparentes sobre los límites: lo que nuestras herramientas hacen y no hacen.

Otro es la esperanza. Crear una herramienta de IA con principios feministas y la aportación de las sobrevivientes es en sí mismo un acto de esperanza. Las participantes nos dijeron que les hacía sentir que la tecnología no es solo algo que les sucede, sino algo que pueden ayudar a crear.

La privacidad también es fundamental. No recopilamos muchos datos de los usuarios, por lo que a menudo medimos el éxito por el número de usuarios y los comentarios, en lugar de por análisis personales. Las primeras respuestas muestran que nuestra plataforma ayuda a las sobrevivientes a recopilar sus historias para que no tengan que repetirlas y a comprender las políticas de la plataforma, proporcionando resúmenes claros de cómo esas políticas se relacionan con el abuso que han sufrido.

**P: Hablando de la recopilación de datos, el debate en torno al cifrado y la seguridad infantil se describe a menudo como una disyuntiva entre la privacidad y la protección. ¿Por qué cree que este planteamiento es problemático?**

R: Porque los niños también merecen privacidad. Los niños tienen sus propios derechos digitales y, cuando crecen, se convierten en adultos que también merecen privacidad. Por supuesto, los niños necesitan protección y salvaguarda porque no siempre pueden tomar decisiones informadas, pero es fácil que esa preocupación se convierta en vigilancia.

La seguridad debe basarse en el respeto de la privacidad de todos, incluidos los niños. No existe realmente un equilibrio entre la seguridad y la privacidad; plantearlo de esa manera es engañoso.

Por ejemplo, un niño de hoy puede crecer y unirse a las protestas climáticas cuando sea adolescente. Si sus antiguos mensajes son accesibles para un gobierno que ahora criminaliza esas protestas, esos chats privados podrían ponerlo en peligro. Por eso son importantes los derechos de privacidad, tanto para los niños de ahora como para los adultos en los que se convertirán.

**P: Y, en cierto sentido, ¿cómo puede el cifrado servir como herramienta de empoderamiento para las mujeres, las sobrevivientes u otras personas en circunstancias vulnerables, en lugar de ser visto como un obstáculo para la seguridad?**

Pero, ¿puede la seguridad en sí misma ser radical? ¿Puede el cifrado, tan a menudo descrito como secreto o aislamiento, convertirse en un instrumento de cuidado colectivo, incluso de democracia?

R: El cifrado proporciona una seguridad fundamental. Permite a las personas mantener la confidencialidad de la información, no solo frente a parejas abusivas, sino también frente a gobiernos u otros actores malintencionados.

Las mujeres y las niñas son ciudadanas de pleno derecho y merecen espacios privados y confidenciales. Proteger esa privacidad no significa ignorar la necesidad de seguridad, sino reconocer que la mayor parte del trabajo de protección debe realizarse fuera de los espacios cifrados.

**P: ¿Tienes ejemplos reales en los que las herramientas cifradas o centradas en la privacidad hayan contribuido a la seguridad y la autonomía de personas que se enfrentan a la violencia o la explotación?**

R: Por supuesto. Las plataformas de chat cifradas son utilizadas por proveedores de servicios de aborto desde El Salvador hasta Estados Unidos y México. Las feministas de China, Irán y Rusia utilizan VPN y canales cifrados para organizarse en torno a los derechos corporales y la violencia doméstica.

Las organizaciones que apoyan a las mujeres y los niños también confían en el cifrado para proteger los datos sensibles de los piratas informáticos. No hacerlo puede tener consecuencias devastadoras. Por ejemplo, una aplicación social llamada T, en la que las mujeres compartían información sobre los hombres con los que salían, fue pirateada, lo que expuso a millones de usuarios porque la empresa no había protegido sus datos.

Otro ejemplo: las aplicaciones de seguimiento del ciclo menstrual. Estas contienen información sanitaria sensible. La aplicación Drip, con sede en Berlín, no almacena los datos de los usuarios y protege la privacidad. En algunos países, el simple hecho de registrar datos sobre la salud sexual o reproductiva puede poner en peligro a las mujeres. El cifrado garantiza que esta información no sea utilizada indebidamente por personas malintencionadas.

**P: ¿Cuál es tu visión sobre Chayn? Como la ves cuando piensas en ella?** 

Muchas sobrevivientes describen la seguridad no solo como «protección contra el daño», sino como la capacidad de hablar, retirarse o configurar las condiciones del diálogo. ¿Cómo podría esta idea más fluida y basada en la agencia de la seguridad transformar la forma en que diseñamos los espacios digitales participativos o deliberativos, donde las asimetrías de poder y la exposición emocional son inherentes?

R: Veo Chayn como un ejercicio de esperanza, solidaridad y reivindicación feminista. Las mujeres tienen derecho a recibir información precisa y práctica sobre sus derechos, su salud mental y su seguridad que no esté enmarcada en un contexto patriarcal.

Deben poder utilizar Internet libremente: para aprender, trabajar, compartir fotos, expresar opiniones, crear negocios, enamorarse y desenamorarse, formar familias y vivir sin acoso. Todas las mujeres, independientemente de su origen, raza, sexualidad o capacidad, merecen esa libertad en espacios digitales seguros.

**P: Muchos gobiernos y plataformas justifican la vigilancia como necesaria para la seguridad. ¿Pueden las tecnologías feministas resistirse a ello sin dejar de centrarse en la protección de los niños y el bienestar de las víctimas?**

En el proyecto INSPIRE, trabajamos en la creación de espacios digitales seguros (o más seguros) para la participación democrática (entendiendo que la «seguridad» es siempre un proceso, no una condición fija); espacios que sean inclusivos, interseccionales y transparentes, pero también seguros desde el punto de vista emocional y psicológico. Según tu experiencia, ¿cuáles diría que son las dimensiones más ignoradas de la «seguridad» en los espacios de participación digital?

R: La función de un gobierno es proteger a los ciudadanos, pero esa protección debe centrarse en los ámbitos en los que tiene autoridad legítima. Eso significa mejorar la aplicación de la ley, formar a la policía para que sepa cómo actuar ante los abusos en línea y garantizar que los sistemas judiciales funcionen de manera eficiente.

Los supervivientes suelen esperar cinco o seis años para que se resuelvan casos sencillos. Muchas denuncias, especialmente las de las trabajadoras sexuales, nunca se toman en serio. Los gobiernos deberían centrar sus recursos en la prevención de la violencia, no en la vigilancia masiva.

La protección real proviene de la educación, el cambio cultural y unas instituciones sólidas, no del acceso a los mensajes de WhatsApp de todo el mundo.

**P: ¿Cuál cree que es el impacto político de esta protección en nuestro mundo democrático?**

Nuestro Marco de Espacios Seguros (o más seguros) también hace hincapié en la responsabilidad institucional, garantizando que las organizaciones que acogen la participación digital se ocupen de las implicaciones emocionales y éticas del espacio, y no solo de su configuración técnica. Según su experiencia, ¿cómo pueden las instituciones adoptar prácticas de gobernanza centradas en los supervivientes y que tengan en cuenta el trauma a la hora de moderar o facilitar el diálogo en línea?

R: Entiendo la tentación de los gobiernos de querer acceder a datos privados. Desde el punto de vista político, es tentador pensar que se podrían resolver los delitos rápidamente si se pudiera ver todo. Pero ahí es donde los gobiernos se extralimitan.

El Estado debe ser una red de seguridad, no un padre. E incluso los padres no deberían vigilar a sus hijos. Los gobiernos no siempre son benevolentes o justos; contienen injusticias sistémicas, discriminación y corrupción.

Los ciudadanos ya comparten mucha información: documentos de identidad, registros, datos en los sistemas policiales, e incluso eso no siempre se gestiona bien. Dar acceso total a los gobiernos crearía un desequilibrio de poder inaceptable. Es el sueño de cualquier sistema de vigilancia, pero nunca debería hacerse realidad.

**P: Usted lleva mucho tiempo defendiendo el código abierto como forma de democratizar el conocimiento. ¿Cómo concilia eso con la idea de protección?**

R: No veo ninguna contradicción entre el acceso abierto y la privacidad. La investigación y los datos financiados con fondos públicos deben ser accesibles al público. Los pagan los ciudadanos, por lo que les pertenecen.

Pero las comunicaciones personales, como las charlas con la familia, son privadas. Pertenecen al ámbito privado, no al público. La transparencia en la gobernanza no significa exponer la vida privada de las personas.

**P: ¿Cuáles son las ventajas y los retos de aplicar los principios del código abierto a ámbitos delicados como la violencia de género o la protección infantil?**

R: Sin duda, requiere una gestión cuidadosa. En Chayn, minimizamos la recopilación de datos. La mayoría de nuestros recursos son abiertos y no requieren inicio de sesión. Tenemos un servicio que incluye una función de chat, y comunicamos claramente a las víctimas que los registros del chat se conservan durante seis meses y luego se eliminan. Esto es tanto por motivos de continuidad como para proteger la privacidad. No queremos datos que puedan ser requeridos por los tribunales.

Somos transparentes al respecto, porque es fundamental proteger la salud mental y la privacidad de las sobrevivientes. Al mismo tiempo, todos nuestros recursos tienen licencia abierta, por lo que otras organizaciones pueden reutilizarlos y adaptarlos. De esta manera, contribuimos al conocimiento global sin restringir el acceso y, al mismo tiempo, protegemos la información privada.

**P: Última pregunta... ¿Cómo pueden los movimientos por los derechos digitales y la justicia de género aprender unos de otros para construir ecosistemas digitales más resilientes y equitativos?**

R: Hay mucho que ambos pueden aprender y muy pocos espacios en los que se cruzan.

Los marcos de derechos digitales pueden ayudar a las organizaciones de justicia de género a comprender cómo el poder, el dinero y la tecnología dan forma a las cuestiones sociales. A la inversa, el movimiento por los derechos digitales puede aprender del trabajo feminista y de justicia de género sobre cómo los daños digitales afectan de manera diferente a las mujeres, las niñas y los niños, y cómo diseñar sistemas más seguros e inclusivos.

No solo debemos reaccionar ante el daño, sino también crear espacios digitales donde puedan suceder cosas buenas de forma segura, creativa y libre.
